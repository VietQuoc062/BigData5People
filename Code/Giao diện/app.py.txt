import streamlit as st
import pandas as pd
import plotly.express as px
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import os
import subprocess
import datetime

# ==============================
# üõ†Ô∏è C·∫•u h√¨nh v√† H√†m chung
# ==============================
st.set_page_config(page_title="IT Job Data Visualization", layout="wide")
st.title("üìä H·ªÜ TH·ªêNG TR·ª∞C QUAN H√ìA D·ªÆ LI·ªÜU TUY·ªÇN D·ª§NG IT VI·ªÜT NAM")
st.markdown("Phi√™n b·∫£n t·ªïng quan t·∫≠p trung v√†o c√°c ph√¢n t√≠ch c·ªët l√µi v·ªÅ th·ªã tr∆∞·ªùng.")

DATA_PATH = "Data/"
BACKUP_PATH = os.path.join(DATA_PATH, "backup")
os.makedirs(BACKUP_PATH, exist_ok=True)

# ==============================
# üõ† H√†m ti·ªán √≠ch
# ==============================
@st.cache_data
def load_all_data():
    files = {
        "salary_stat": "salary_stat.csv",
        "level_count": "level_count.csv",
        "domain_count": "domain_count.csv",
        "skill_count": "skill_count.csv",
        "salary_location": "salary_location.csv",
        "company_job_count": "company_job_count.csv",
    }
    dataframes = {}
    for key, filename in files.items():
        filepath = os.path.join(DATA_PATH, filename)
        try:
            df = pd.read_csv(filepath, sep=";", header=None)
        except UnicodeDecodeError:
            df = pd.read_csv(filepath, sep=";", encoding="cp1252", header=None)
        except FileNotFoundError:
            st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y file {filename} trong th∆∞ m·ª•c '{DATA_PATH}'.")
            df = pd.DataFrame()
        dataframes[key] = df
    return dataframes

def clean_salary_column(series):
    series = series.astype(str).str.replace(" tri·ªáu VND", "", regex=False)
    series = series.str.replace("th∆∞∆°ng l∆∞·ª£ng", "", regex=False)
    series = series.str.replace(",", ".", regex=False)
    series = series.str.replace(r'[^\d\.\-]', '', regex=True)
    return pd.to_numeric(series, errors="coerce")

def convert_df_to_csv(df):
    return df.to_csv(index=False).encode('utf-8')

def backup_file(file_name):
    df = pd.read_csv(os.path.join(DATA_PATH, file_name))
    if df.empty:
        return None, None
    backup_dir = os.path.join(BACKUP_PATH, file_name.replace(".csv",""))
    os.makedirs(backup_dir, exist_ok=True)
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_file_name = f"{file_name.replace('.csv','')}_{timestamp}.csv"
    backup_path = os.path.join(backup_dir, backup_file_name)
    df.to_csv(backup_path, index=False)
    return backup_file_name, backup_path

def restore_file(file_name, backup_file_name):
    backup_dir = os.path.join(BACKUP_PATH, file_name.replace(".csv",""))
    backup_path = os.path.join(backup_dir, backup_file_name)
    if not os.path.exists(backup_path):
        return False
    df = pd.read_csv(backup_path)
    df.to_csv(os.path.join(DATA_PATH, file_name), index=False)
    return True

# ==============================
# üîπ Sidebar ch·ªçn ch·ª©c nƒÉng
# ==============================
st.sidebar.header("Ch·ªçn Ch·ª©c NƒÉng")
analysis_selection = st.sidebar.radio(
    "Ch·ªçn m·ªôt nh√≥m ƒë·ªÉ xem chi ti·∫øt:",
    (
        "üí∞ Ph√¢n T√≠ch L∆∞∆°ng", 
        "üìà Ph√¢n T√≠ch Nhu C·∫ßu Tuy·ªÉn D·ª•ng", 
        "üè¢ Th√¥ng Tin Th·ªã Tr∆∞·ªùng", 
        "‚öôÔ∏è Qu·∫£n L√Ω Data & final_cleaned", 
        "üîÑ Qu·∫£n L√Ω File HDFS",
        "üíæ Backup & Restore"
    )
)

# ==============================
# üí∞ Ph√¢n T√≠ch L∆∞∆°ng
# ==============================
if analysis_selection == "üí∞ Ph√¢n T√≠ch L∆∞∆°ng":
    st.header("üí∞ Ph√¢n T√≠ch L∆∞∆°ng")
    df_salary = load_all_data()["salary_stat"].copy()
    if not df_salary.empty and len(df_salary.columns) >= 4:
        df_salary.columns = ["Job", "Count", "Variance", "Std"]
        for col in ["Count","Variance","Std"]:
            df_salary[col] = pd.to_numeric(df_salary[col].astype(str).str.replace(",", "", regex=False), errors="coerce").fillna(0)
        df_salary_nonzero = df_salary[df_salary["Std"]>0].sort_values("Std", ascending=False)
        top_n = st.slider("Top N c√¥ng vi·ªác theo bi·∫øn ƒë·ªông l∆∞∆°ng", 5, min(30,len(df_salary_nonzero)), 15)
        df_top = df_salary_nonzero.head(top_n)
        fig = px.bar(df_top, x="Job", y="Std", color="Std",
                     text=df_top["Std"].apply(lambda x:f"{x:,.0f}"), title=f"Top {top_n} c√¥ng vi·ªác theo ƒë·ªô l·ªách chu·∫©n l∆∞∆°ng")
        fig.update_layout(xaxis_tickangle=-45, coloraxis_showscale=False, uniformtext_minsize=8, uniformtext_mode='hide')
        fig.update_traces(textposition='outside')
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.error("D·ªØ li·ªáu salary_stat.csv kh√¥ng h·ª£p l·ªá")

    df_loc = load_all_data()["salary_location"].copy()
    if not df_loc.empty and len(df_loc.columns)>=3:
        df_loc.columns=["KhuVuc","SoLuongTin","LuongTB"]
        df_loc["LuongTB"]=clean_salary_column(df_loc["LuongTB"])
        df_loc.dropna(subset=["LuongTB"], inplace=True)
        df_loc = df_loc[df_loc["LuongTB"]>0].sort_values("LuongTB", ascending=False)
        fig_loc = px.bar(df_loc, x="KhuVuc", y="LuongTB", color="LuongTB",
                         title="M·ª©c l∆∞∆°ng trung b√¨nh theo khu v·ª±c (tri·ªáu VND)")
        fig_loc.update_traces(texttemplate='%{y:.1f} tr', textposition='outside')
        st.plotly_chart(fig_loc, use_container_width=True)

# ==============================
# üìà Ph√¢n T√≠ch Nhu C·∫ßu Tuy·ªÉn D·ª•ng
# ==============================
elif analysis_selection == "üìà Ph√¢n T√≠ch Nhu C·∫ßu Tuy·ªÉn D·ª•ng":
    st.header("üìà Ph√¢n T√≠ch Nhu C·∫ßu Tuy·ªÉn D·ª•ng")
    df_level = load_all_data()["level_count"].copy()
    if not df_level.empty and len(df_level.columns)>=2:
        df_level.columns=["CapDo","SoLuong"]
        df_level["SoLuong"]=pd.to_numeric(df_level["SoLuong"], errors="coerce").fillna(0)
        df_level = df_level[df_level["SoLuong"]>0]
        fig = px.pie(df_level, names="CapDo", values="SoLuong", hole=0.4, title="T·ª∑ l·ªá nhu c·∫ßu theo c·∫•p ƒë·ªô")
        fig.update_traces(textinfo='percent+label')
        st.plotly_chart(fig, use_container_width=True)

    df_domain = load_all_data()["domain_count"].copy()
    if not df_domain.empty and len(df_domain.columns)>=2:
        df_domain.columns=["LinhVuc","SoLuong"]
        df_domain["SoLuong"]=pd.to_numeric(df_domain["SoLuong"], errors="coerce").fillna(0)
        top_n = st.slider("Top N lƒ©nh v·ª±c",5,15,8,key="domain_slider")
        df_top = df_domain.sort_values("SoLuong", ascending=False).head(top_n)
        fig = px.bar(df_top, x="SoLuong", y="LinhVuc", orientation='h', color="SoLuong",
                     title=f"Top {top_n} lƒ©nh v·ª±c c√≥ nhu c·∫ßu tuy·ªÉn d·ª•ng nhi·ªÅu nh·∫•t")
        st.plotly_chart(fig, use_container_width=True)

    df_skill = load_all_data()["skill_count"].copy()
    if not df_skill.empty and len(df_skill.columns)>=2:
        df_skill.columns=["KyNang","SoLuong"]
        df_skill["SoLuong"]=pd.to_numeric(df_skill["SoLuong"], errors="coerce").fillna(0)
        top_skills = df_skill.sort_values("SoLuong", ascending=False).head(100)
        wc_dict = top_skills.set_index("KyNang")["SoLuong"].to_dict()
        wc = WordCloud(width=800,height=400, background_color="white", max_words=100,colormap='viridis').generate_from_frequencies(wc_dict)
        fig,ax = plt.subplots(figsize=(12,6))
        ax.imshow(wc, interpolation="bilinear")
        ax.axis("off")
        st.pyplot(fig)

# ==============================
# üè¢ Th√¥ng Tin Th·ªã Tr∆∞·ªùng
# ==============================
elif analysis_selection == "üè¢ Th√¥ng Tin Th·ªã Tr∆∞·ªùng":
    st.header("üè¢ Th√¥ng Tin Th·ªã Tr∆∞·ªùng")
    df_company = load_all_data()["company_job_count"].copy()
    if not df_company.empty and len(df_company.columns)>=2:
        df_company.columns=["CongTy","SoLuongTin"]
        df_company["SoLuongTin"]=pd.to_numeric(df_company["SoLuongTin"], errors="coerce").fillna(0)
        top_n = st.slider("Top N c√¥ng ty",5,30,15,key="company_slider")
        df_top = df_company.sort_values("SoLuongTin", ascending=False).head(top_n)
        fig = px.bar(df_top, x="SoLuongTin", y="CongTy", orientation='h', color="SoLuongTin",
                     title=f"Top {top_n} c√¥ng ty c√≥ nhi·ªÅu tin tuy·ªÉn d·ª•ng nh·∫•t")
        st.plotly_chart(fig, use_container_width=True)

# ==============================
# ‚öôÔ∏è Qu·∫£n L√Ω Data & final_cleaned
# ==============================
elif analysis_selection == "‚öôÔ∏è Qu·∫£n L√Ω Data & final_cleaned":
    st.header("‚öôÔ∏è Qu·∫£n L√Ω & Ch·ªânh S·ª≠a File 'final_cleaned.csv'")
    FINAL_FILE = os.path.join(DATA_PATH,"final_cleaned.csv")
    HDFS_PATH = "hdfs://localhost:9000/input/final_cleaned.csv"
    try:
        df_final = pd.read_csv(FINAL_FILE)
    except:
        df_final=pd.DataFrame()
    if not df_final.empty:
        search_term = st.text_input("T√¨m ki·∫øm trong b·∫£ng:").strip()
        df_display = df_final.copy()
        if search_term:
            mask = df_display.apply(lambda row: row.astype(str).str.contains(search_term, case=False).any(), axis=1)
            df_display=df_display[mask]
        st.markdown("### ‚úèÔ∏è Ch·ªânh s·ª≠a d·ªØ li·ªáu tr·ª±c ti·∫øp")
        edited_df = st.data_editor(df_display,num_rows="dynamic", use_container_width=True)
        if st.button("üíæ L∆∞u thay ƒë·ªïi v√†o file local"):
            if search_term:
                for idx in edited_df.index:
                    df_final.loc[idx]=edited_df.loc[idx]
            else:
                df_final=edited_df.copy()
            df_final.to_csv(FINAL_FILE,index=False)
            st.success(f"‚úÖ ƒê√£ l∆∞u file final_cleaned.csv t·∫°i {FINAL_FILE}")
        st.markdown("### ‚¨ÜÔ∏è C·∫≠p nh·∫≠t file l√™n HDFS")
        if st.button("üöÄ C·∫≠p nh·∫≠t l√™n HDFS"):
            try:
                df_final.to_csv(FINAL_FILE,index=False)
                cmd=f"hdfs dfs -put -f {FINAL_FILE} {HDFS_PATH}"
                subprocess.run(cmd, shell=True, check=True)
                st.success(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t file l√™n HDFS: {HDFS_PATH}")
            except subprocess.CalledProcessError as e:
                st.error(f"‚ùå L·ªói khi c·∫≠p nh·∫≠t l√™n HDFS: {e}")

# ==============================
# üîÑ Qu·∫£n L√Ω File HDFS
# ==============================
elif analysis_selection == "üîÑ Qu·∫£n L√Ω File HDFS":
    st.header("üîÑ Qu·∫£n L√Ω File HDFS")
    LOCAL_DATA_PATH = DATA_PATH
    st.subheader("1Ô∏è‚É£ Import t·ª´ HDFS v·ªÅ local")
    hdfs_file_to_import = st.text_input("ƒê∆∞·ªùng d·∫´n file HDFS:", value="/input/final_cleaned.csv", key="import_hdfs")
    if st.button("‚¨áÔ∏è T·∫£i v·ªÅ local"):
        local_target = os.path.join(LOCAL_DATA_PATH, os.path.basename(hdfs_file_to_import))
        try:
            cmd = f"hdfs dfs -get -f {hdfs_file_to_import} {local_target}"
            subprocess.run(cmd, shell=True, check=True)
            st.success(f"‚úÖ File ƒë√£ ƒë∆∞·ª£c t·∫£i v·ªÅ: {local_target}")
        except subprocess.CalledProcessError as e:
            st.error(f"‚ùå L·ªói khi t·∫£i file t·ª´ HDFS: {e}")

    st.markdown("---")
    st.subheader("2Ô∏è‚É£ Export t·ª´ local l√™n HDFS")
    local_files = [f for f in os.listdir(LOCAL_DATA_PATH) if os.path.isfile(os.path.join(LOCAL_DATA_PATH,f))]
    file_to_export = st.selectbox("Ch·ªçn file local ƒë·ªÉ upload:", local_files, key="export_local")
    hdfs_target_path = st.text_input("ƒê∆∞·ªùng d·∫´n ƒë√≠ch tr√™n HDFS:", value="/input/", key="export_hdfs")
    if st.button("‚¨ÜÔ∏è Upload l√™n HDFS"):
        local_path = os.path.join(LOCAL_DATA_PATH, file_to_export)
        hdfs_full_path = os.path.join(hdfs_target_path, file_to_export)
        try:
            cmd = f"hdfs dfs -put -f {local_path} {hdfs_full_path}"
            subprocess.run(cmd, shell=True, check=True)
            st.success(f"‚úÖ File ƒë√£ ƒë∆∞·ª£c upload l√™n HDFS: {hdfs_full_path}")
        except subprocess.CalledProcessError as e:
            st.error(f"‚ùå L·ªói khi upload file l√™n HDFS: {e}")

# ==============================
# üíæ Backup & Restore
# ==============================
elif analysis_selection == "üíæ Backup & Restore":
    st.header("üíæ Backup & Restore File CSV")

    csv_files = [f for f in os.listdir(DATA_PATH) if f.endswith(".csv")]
    file_selected = st.selectbox("Ch·ªçn file mu·ªën backup/restore:", csv_files, key="backup_file_select")

    st.subheader("1Ô∏è‚É£ Backup file local")
    if st.button("üíæ T·∫°o backup"):
        backup_name, backup_path = backup_file(file_selected)
        if backup_name:
            st.success(f"‚úÖ ƒê√£ t·∫°o backup: {backup_name} t·∫°i {backup_path}")
        else:
            st.warning("‚ùå File r·ªóng, kh√¥ng th·ªÉ backup.")

    st.subheader("2Ô∏è‚É£ Restore t·ª´ local backup")
    backup_dir = os.path.join(BACKUP_PATH, file_selected.replace(".csv",""))
    backups = []
    if os.path.exists(backup_dir):
        backups = [f for f in os.listdir(backup_dir) if f.endswith(".csv")]
    restore_backup = st.selectbox("Ch·ªçn backup ƒë·ªÉ restore:", backups, key="restore_backup")
    if st.button("‚ôªÔ∏è Restore file"):
        if restore_file(file_selected, restore_backup):
            st.success(f"‚úÖ ƒê√£ restore {file_selected} t·ª´ backup {restore_backup}")
        else:
            st.error("‚ùå L·ªói restore file")


# ==============================
# Footer
# ==============================
st.markdown("---")
st.caption("¬© 2025 - IT Job Data Visualization | Ngu·ªìn d·ªØ li·ªáu: itviec.com & topdev.vn")
